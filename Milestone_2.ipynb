{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental Impact of Agricultural Practices in the World\n",
    "\n",
    "**ADA Project Milestone 2**\n",
    "\n",
    "This notebook consists of our initial Data Analysis of the FAOSTAT dataset on Food an agriculture. We will first study the contents of the data and its strucuture, before restructuring it in order to start our analysis. Also, some research questions initially asked will be answered by the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Initial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset initially contained 78 csv files, but some of them were discarded as they will not be useful for our analysis. We have selected 43 CSVs that would help us with our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = glob('data/**/**.csv')\n",
    "len(csv_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split those 43 csv into different directories, one for each group of csv. Each group corresponds to one category:\n",
    "```.\n",
    "+-- data/\n",
    "|   +-- emissions_agriculture/\n",
    "|      +-- ...\n",
    "|   +-- emissions_land/\n",
    "|      +-- ...\n",
    "|   +-- environment/\n",
    "|      +-- ...\n",
    "|   +-- forestry/\n",
    "|      +-- ...\n",
    "|   +-- inputs/\n",
    "|      +-- ...\n",
    "|   +-- population/\n",
    "|      +-- ...\n",
    "|   +-- production/\n",
    "|      +-- ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### A.1 Schema consistency\n",
    "---\n",
    "\n",
    "We will first study the schemas of all the csv files we have in order to see if they are consistent or require changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Checking column names across whole dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's scan all the csv files and check their schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The found columns, grouped, are:\n",
      "\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'item', 'itemcode', 'unit', 'value', 'year', 'yearcode'] Num files 33\n",
      "['country', 'countrycode', 'element', 'elementcode', 'elementgroup', 'flag', 'item', 'itemcode', 'unit', 'value', 'year'] Num files 4\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'months', 'monthscode', 'unit', 'value', 'year', 'yearcode'] Num files 1\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'item', 'itemcode', 'note', 'unit', 'value', 'year', 'yearcode'] Num files 4\n",
      "['country', 'countrycode', 'element', 'elementcode', 'flag', 'item', 'itemcode', 'unit', 'value', 'year', 'yearcode'] Num files 1\n"
     ]
    }
   ],
   "source": [
    "from data_processing import scan_columns\n",
    "all_columns = scan_columns(csv_files)\n",
    "print(\"The found columns, grouped, are:\\n\")\n",
    "for cols, f in all_columns:\n",
    "    print(list(sorted(cols)), f\"Num files {len(f)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, sometimes the columns `area` and `areacode` are named `country` and `countrycode`, only because some csv files only contain country data, without country groups. We will rename those as to have a unified schema. Also, some files have the `note`, `elementgroup` and `months` columns. We will look into those in subsequent steps as we are now simply checking whether column naming is consistent.\n",
    "\n",
    "In order to obtain a more consistent column naming, we will rename `country` to `area` and `countrycode` to `areacode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_rename = {'country': 'area', 'countrycode': 'areacode'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After renaming, we obtain the following columns:\n",
      "\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'item', 'itemcode', 'unit', 'value', 'year', 'yearcode'] Num files 34\n",
      "['area', 'areacode', 'element', 'elementcode', 'elementgroup', 'flag', 'item', 'itemcode', 'unit', 'value', 'year'] Num files 4\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'months', 'monthscode', 'unit', 'value', 'year', 'yearcode'] Num files 1\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'item', 'itemcode', 'note', 'unit', 'value', 'year', 'yearcode'] Num files 4\n"
     ]
    }
   ],
   "source": [
    "all_columns_2 = scan_columns(csv_files, column_rename)\n",
    "print(f\"After renaming, we obtain the following columns:\\n\")\n",
    "for cols, f in all_columns_2:\n",
    "    print(list(sorted(cols)), f\"Num files {len(f)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Checking which columns to drop\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a few files that have different schemas. One column that we should look into before continuing is `note`, as it is in 4 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([nan]), array([nan]), array([nan]), array([nan])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_processing import load_dataframe\n",
    "def get_column_unique_values(files, col):\n",
    "    # Function that returns the unique values of a column across multiple files\n",
    "    values = []\n",
    "    for f in files:\n",
    "        df = load_dataframe(f, column_rename)\n",
    "        vals = df[col].unique()\n",
    "        values.append(vals)\n",
    "    return values\n",
    "\n",
    "files_with_note = all_columns_2[-1][1]\n",
    "note_values = get_column_unique_values(files_with_note, 'note')\n",
    "note_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, all values for this column are NaN, so we can safely drop the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Checking duplicate columns\n",
    "---\n",
    "\n",
    "We figured it would be useful to scan for duplicate columns in each dataframe (i.e. columns with different names but same values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates for [('yearcode', 'year')] in 39 files\n",
      "Duplicates for [('elementgroup', 'elementcode')] in 3 files\n"
     ]
    }
   ],
   "source": [
    "from data_processing import scan_column_duplicates\n",
    "duplicates = scan_column_duplicates(csv_files, column_rename)\n",
    "for c, f in duplicates:\n",
    "    print(f\"Duplicates for {c} in {len(f)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, most files have `year` and `yearcode` columns which are equal. Hence, we can safely drop this column. However, for `elementgroup` and `elementcode`, they are equal in almost all CSV where they appear (3/4), but not all, so we cannot safely drop it without checking. We choose to keep `elementcode` when those two are equal, and keep them both when they are not.\n",
    "\n",
    "Hence, we can define a list of columns to be dropped, but we need to check if they fulfill any of the following conditions:\n",
    " - NaN in all rows\n",
    " - Duplicate with another column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After renaming and dropping columns, we obtain the following columns:\n",
      "\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'item', 'itemcode', 'unit', 'value', 'year'] Num files 41\n",
      "['area', 'areacode', 'element', 'elementcode', 'elementgroup', 'flag', 'item', 'itemcode', 'unit', 'value', 'year'] Num files 1\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'months', 'monthscode', 'unit', 'value', 'year'] Num files 1\n"
     ]
    }
   ],
   "source": [
    "drop_columns = [\"note\", \"yearcode\", \"elementgroup\"]\n",
    "all_columns_3 = scan_columns(csv_files, column_rename, drop_columns)\n",
    "print(f\"After renaming and dropping columns, we obtain the following columns:\\n\")\n",
    "for cols, f in all_columns_3:\n",
    "    print(list(sorted(cols)), f\"Num files {len(f)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 41 files with identical schemas, and 2 files that have a different one:\n",
    " - The file containing the `elementgroup` additional column \n",
    " - The file with monthly data and no `item` and `itemcode` columns\n",
    " \n",
    "To obtain the desired format, we can now call `load_dataframe(<file>, column_rename, drop_columns)` with `column_rename = {'country': 'area', 'countrycode': 'areacode'}` and `drop_columns = [\"note\", \"yearcode\", \"elementgroup\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### A.2 Schema description\n",
    "\n",
    "---\n",
    "Now that we have a unified schema for (almost) all csv files, we can start looking into the meaning of each column and their possible value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Area columns\n",
    "---\n",
    "We will first look into the columns `area` and `areacode`. According to FAOSTAT's website, each area is defined by a unique areacode, however some areas include other ones, i.e. there are grouped areas in the datasets. We would expect a one-to-one mapping between those two columns. Let's see how this looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that it is indeed a one-to-one mapping, we will append all values from all csv files, and drop duplicates. Then we group by area and see if the length of the group is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_processing import get_column_unique_values\n",
    "from utils import is_unique_mapping\n",
    "\n",
    "area_values = get_column_unique_values(csv_files, column_rename, drop_columns, ['area', 'areacode'])\n",
    "is_unique_mapping(area_values, 'area', 'areacode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the mapping is not one-to-one. Let's look into why that is. First we group by `areacode` and aggregate to a list of `area` and then we do the inverse. This way, we can see how the mapping is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: areacode, dtype: object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grpd = area_values.groupby('area')['areacode'].apply(list)\n",
    "grpd[grpd.apply(lambda x: len(x) > 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mapping `area` -> `areacode` is unique, now for the opposite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "areacode\n",
       "35                               [Cabo Verde, Cape Verde]\n",
       "151     [Netherlands Antilles (former), Netherlands An...\n",
       "154     [The former Yugoslav Republic of Macedonia, No...\n",
       "167                             [Czechia, Czech Republic]\n",
       "209                                 [Eswatini, Swaziland]\n",
       "299           [Occupied Palestinian Territory, Palestine]\n",
       "5000                             [World, World + (Total)]\n",
       "5100                           [Africa, Africa + (Total)]\n",
       "5101           [Eastern Africa, Eastern Africa + (Total)]\n",
       "5102             [Middle Africa, Middle Africa + (Total)]\n",
       "5103         [Northern Africa, Northern Africa + (Total)]\n",
       "5104         [Southern Africa, Southern Africa + (Total)]\n",
       "5105           [Western Africa, Western Africa + (Total)]\n",
       "5200                       [Americas, Americas + (Total)]\n",
       "5203       [Northern America, Northern America + (Total)]\n",
       "5204         [Central America, Central America + (Total)]\n",
       "5206                     [Caribbean, Caribbean + (Total)]\n",
       "5207             [South America, South America + (Total)]\n",
       "5300                               [Asia, Asia + (Total)]\n",
       "5301               [Central Asia, Central Asia + (Total)]\n",
       "5302               [Eastern Asia, Eastern Asia + (Total)]\n",
       "5303             [Southern Asia, Southern Asia + (Total)]\n",
       "5304    [South-Eastern Asia, South-Eastern Asia + (Tot...\n",
       "5305               [Western Asia, Western Asia + (Total)]\n",
       "5400                           [Europe, Europe + (Total)]\n",
       "5401           [Eastern Europe, Eastern Europe + (Total)]\n",
       "5402         [Northern Europe, Northern Europe + (Total)]\n",
       "5403         [Southern Europe, Southern Europe + (Total)]\n",
       "5404           [Western Europe, Western Europe + (Total)]\n",
       "5500                         [Oceania, Oceania + (Total)]\n",
       "5501    [Australia & New Zealand, Australia and New Ze...\n",
       "5502                     [Melanesia, Melanesia + (Total)]\n",
       "5504                     [Polynesia, Polynesia + (Total)]\n",
       "5706           [European Union, European Union + (Total)]\n",
       "5801    [Least Developed Countries, Least Developed Co...\n",
       "5802    [Land Locked Developing Countries, LandLocked ...\n",
       "5803    [Small Island Developing States, Small Island ...\n",
       "5815    [Low Income Food Deficit Countries, Low Income...\n",
       "5817    [Net Food Importing Developing Countries, Net ...\n",
       "Name: area, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grpd = area_values.groupby('areacode')['area'].apply(list)\n",
    "grpd[grpd.apply(lambda x: len(x) > 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the same `areacode` is sometimes mapped to multiple `area`, most of the time by adding \"+ (Total)\". For that, we could drop the `area` column and keep working with `areacode`.\n",
    "\n",
    "However, we still need a fixed database that maps the `areacode` to `area`, and for this, FAOSTAT provides one CSV file containing the mapping, as well as another one containing a description of country groups (i.e. \"Asia\") and which contries they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countrygroupcode</th>\n",
       "      <th>countrygroup</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>country</th>\n",
       "      <th>m49code</th>\n",
       "      <th>iso2code</th>\n",
       "      <th>iso3code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>4</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>12.0</td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>7</td>\n",
       "      <td>Angola</td>\n",
       "      <td>24.0</td>\n",
       "      <td>AO</td>\n",
       "      <td>AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>53</td>\n",
       "      <td>Benin</td>\n",
       "      <td>204.0</td>\n",
       "      <td>BJ</td>\n",
       "      <td>BEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>20</td>\n",
       "      <td>Botswana</td>\n",
       "      <td>72.0</td>\n",
       "      <td>BW</td>\n",
       "      <td>BWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>British Indian Ocean Territory</td>\n",
       "      <td>86.0</td>\n",
       "      <td>IO</td>\n",
       "      <td>IOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   countrygroupcode countrygroup  countrycode                         country  \\\n",
       "0              5100       Africa            4                         Algeria   \n",
       "1              5100       Africa            7                          Angola   \n",
       "2              5100       Africa           53                           Benin   \n",
       "3              5100       Africa           20                        Botswana   \n",
       "4              5100       Africa           24  British Indian Ocean Territory   \n",
       "\n",
       "   m49code iso2code iso3code  \n",
       "0     12.0       DZ      DZA  \n",
       "1     24.0       AO      AGO  \n",
       "2    204.0       BJ      BEN  \n",
       "3     72.0       BW      BWA  \n",
       "4     86.0       IO      IOT  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_codes = load_dataframe('data/countries.csv')\n",
    "country_groups = load_dataframe('data/country_groups.csv')\n",
    "country_groups.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, countries are grouped into multiple `countrygroup`, so we know exactly of which countries each group is formed. These country groups are present in the dataset as `area`, meaning there are aggregated values in the dataset. For example: we can find the emissions for \"Algeria\" and for \"Africa\", where the latter is an aggregated value over the whole group. We will need to be careful when aggregating values in the future, as we could account multiple times for one country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countrycode</th>\n",
       "      <th>country</th>\n",
       "      <th>m49code</th>\n",
       "      <th>iso2code</th>\n",
       "      <th>iso3code</th>\n",
       "      <th>startyear</th>\n",
       "      <th>endyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>284</td>\n",
       "      <td>Ã",
       "land Islands</td>\n",
       "      <td>248.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Albania</td>\n",
       "      <td>8.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>12.0</td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   countrycode         country  m49code iso2code iso3code  startyear  endyear\n",
       "0            2     Afghanistan      4.0       AF      AFG        NaN      NaN\n",
       "1         5100          Africa      2.0      NaN      X06        NaN      NaN\n",
       "2          284  Ã\n",
       "land Islands    248.0      NaN      ALA        NaN      NaN\n",
       "3            3         Albania      8.0       AL      ALB        NaN      NaN\n",
       "4            4         Algeria     12.0       DZ      DZA        NaN      NaN"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe provides a mapping between `countrycode` and `country`, let's check if the mapping is unique, as well as all the values of `areacode` present in the dataset are in `area_codes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_unique_mapping(area_codes[['country', 'countrycode']].drop_duplicates(), 'country', 'countrycode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(x in area_codes.countrycode.unique() for x in area_values.areacode.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we can use the dataframe `country_codes` to obtain the country's name from it's code. For this, we can now drop the `area` column in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Element Columns\n",
    "---\n",
    "\n",
    "The `element` and `elementcode` represent the measure quantity for a given `item`. A quantity has a name and a unit, which is why we believe these two columns should also have a one-to-one mapping accross the whole dataset. Also, since an `elementcode` potentially uniquely identifies (`element`, `unit`) pair, we might drop those two columns as to make the csv files smaller and easier to manipulate.\n",
    "\n",
    "First let's check if indeed this mapping is one-to-one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_values = get_column_unique_values(csv_files, column_rename, drop_columns, ['elementcode', 'element', 'unit'])\n",
    "is_unique_mapping(element_values, 'elementcode', ['element', 'unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elementcode</th>\n",
       "      <th>element</th>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>Head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>5112</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>1000 Head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>5114</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5510</td>\n",
       "      <td>Production</td>\n",
       "      <td>tonnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5313</td>\n",
       "      <td>Laying</td>\n",
       "      <td>1000 Head</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     elementcode     element       unit\n",
       "0           5111      Stocks       Head\n",
       "171         5112      Stocks  1000 Head\n",
       "684         5114      Stocks         No\n",
       "0           5510  Production     tonnes\n",
       "0           5313      Laying  1000 Head"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `elementcode` uniquely identify (`element`, `unit`) pairs, so we can safely drop those two columns and only use `elementcode`. We will later pivot each csv as to obtain all the `elementcode`s as columns, so we can reduce de number of rows significantly. A mapping using a dictionnary will of course be necessary in order to have a nice GUI where users can select the (element, unit) pair instead of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Item columns\n",
    "---\n",
    "\n",
    "According to FAOSTAT, the `item` and `itemcode` columns represent item on which measurements were done. For example an item can be `cattle` and the measurement can be \"CH4 emissions in gigagrams\". \n",
    "Similarly to what we did above, we expect `item` and `itemcode` to have a one-to-one relationship. Let's verify this using the same functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_values = get_column_unique_values(csv_files, column_rename, drop_columns, ['item', 'itemcode'], with_file=True)\n",
    "is_unique_mapping(item_values[['item', 'itemcode']], 'item', 'itemcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that `item` to `itemcode` is not unique for a few items, let's check those and try to understand why it is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: item, dtype: object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grpd = item_values.groupby('itemcode')['item'].agg(set)\n",
    "grpd[grpd.apply(len) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mapping `itemcode` -> `item` is unique, now let's check the other way around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item\n",
       "Ammonium nitrate (AN)                                  {1362, 4003}\n",
       "Ammonium sulphate                                      {1361, 4002}\n",
       "Burning - all categories                               {6795, 6798}\n",
       "Cattle                                                  {866, 1757}\n",
       "Chickens                                               {1057, 1054}\n",
       "Cropland                                               {6620, 5070}\n",
       "Disinfectants                                          {1358, 1351}\n",
       "Forest land                                      {5065, 6749, 6646}\n",
       "Grassland                                              {6794, 6983}\n",
       "Mineral Oils                                           {1354, 1316}\n",
       "Other Pesticides nes                                   {1355, 1359}\n",
       "Other nitrogenous fertilizers, n.e.c.                  {4008, 1369}\n",
       "Other potassic fertilizers, n.e.c.                     {4018, 1391}\n",
       "Plant Growth Regulators                                {1356, 1341}\n",
       "Potassium sulphate (sulphate of potash) (SOP)          {4017, 1387}\n",
       "Urea                                                   {4001, 1367}\n",
       "Name: itemcode, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = item_values.groupby('item')['itemcode'].agg(set)\n",
    "grouped[grouped.apply(len) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some items seem to have multiple (up to 3) different item codes, which doesn't seem very normal. \n",
    "\n",
    "**a.** It seems that some of those items correspond to nutrients provided throught fertilizers. Let's see in which files those appear. The items related to nutrients are the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data/inputs/Inputs_FertilizersArchive_E_All_Data_(Normalized).csv',\n",
       "       'data/inputs/Inputs_FertilizersProduct_E_All_Data_(Normalized).csv'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrient_items = [\"Ammonium nitrate (AN)\", \"Ammonium sulphate\", \"Other nitrogenous fertilizers, n.e.c.\", \"Other potassic fertilizers, n.e.c.\", \"Potassium sulphate (sulphate of potash) (SOP)\", \"Urea\"]\n",
    "item_values[item_values.item.isin(nutrient_items)].file.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those items are only present in two dataframes, related to Ferilizer use. If we look closely at the names of csv files, we can see that one of them is \"Archive\", \n",
    "while the other is product. After having looking and reading the documentation for this CSV [http://www.fao.org/faostat/en/#data/RA], we understand that it is an archive document, that has not been updated since 2002. \n",
    "\n",
    "Before that date, all data on Fertilizer was put into one single dataframe (i.e. info about production, trade and consumption) both in total nutrients and amount of product. After 2002, it was split into nutrient and product, which is why we have two `itemcode` values for those `items`. \n",
    "\n",
    "Hence, we should be careful when studying the fertilizer use, as data collection has changed in 2002.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** Some items are related to pesticides. Let's in which csv files they appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data/inputs/Inputs_Pesticides_Use_E_All_Data_(Normalized).csv'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pesticide_items = [\"Disinfectants\", \"Mineral Oils\", \"Other Pesticides nes\", \"Plant Growth Regulators\"]\n",
    "item_values[item_values.item.isin(pesticide_items)].file.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some duplicate items with the same name but different codes appear in only one csv file, which seems quite odd. We suspect having duplicate rows in that case. Let's check that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate item for Disinfectants codes [1358 1351]\n",
      "Duplicate item for Mineral Oils codes [1354 1316]\n",
      "Duplicate item for Other Pesticides nes codes [1359 1355]\n",
      "Duplicate item for Plant Growth Regulators codes [1356 1341]\n"
     ]
    }
   ],
   "source": [
    "from data_processing import check_duplicate_items\n",
    "t = load_dataframe('data/inputs/Inputs_Pesticides_Use_E_All_Data_(Normalized).csv', column_rename, drop_columns)\n",
    "check_duplicate_items(t, pesticide_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know that there are potentially duplicate rows for the same `item` but a different `itemcode` (with the same measurements). Hence, we need to add a functionnality that checks for duplicated items in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** Now let's look at livestock items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th>itemcode</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Cattle</th>\n",
       "      <th>866</th>\n",
       "      <td>{data/production/Production_Livestock_E_All_Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>{data/emissions_agriculture/Emissions_Agricult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Chickens</th>\n",
       "      <th>1054</th>\n",
       "      <td>{data/emissions_agriculture/Emissions_Agricult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>{data/production/Production_Livestock_E_All_Da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                file\n",
       "item     itemcode                                                   \n",
       "Cattle   866       {data/production/Production_Livestock_E_All_Da...\n",
       "         1757      {data/emissions_agriculture/Emissions_Agricult...\n",
       "Chickens 1054      {data/emissions_agriculture/Emissions_Agricult...\n",
       "         1057      {data/production/Production_Livestock_E_All_Da..."
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livestock_items = [\"Cattle\", \"Chickens\"]\n",
    "item_values[item_values.item.isin(livestock_items)].groupby(['item', 'itemcode']).agg(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `itemcode` -> `item` seems one-to-one in each csv file, but we see that there are two distinct `itemcode` for \"Cattle\" and \"Chickens\" accross all csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['data/production/Production_Livestock_E_All_Data_(Normalized).csv',\n",
       "        866, 'Cattle'],\n",
       "       ['data/production/Production_Livestock_E_All_Data_(Normalized).csv',\n",
       "        1057, 'Chickens'],\n",
       "       ['data/environment/Environment_LivestockPatterns_E_All_Data_(Normalized).csv',\n",
       "        866, 'Cattle'],\n",
       "       ['data/environment/Environment_LivestockPatterns_E_All_Data_(Normalized).csv',\n",
       "        1057, 'Chickens'],\n",
       "       ['data/environment/Environment_LivestockManure_E_All_Data_(Normalized).csv',\n",
       "        1757, 'Cattle'],\n",
       "       ['data/environment/Environment_LivestockManure_E_All_Data_(Normalized).csv',\n",
       "        1054, 'Chickens'],\n",
       "       ['data/emissions_agriculture/Emissions_Agriculture_Enteric_Fermentation_E_All_Data_(Normalized).csv',\n",
       "        1757, 'Cattle'],\n",
       "       ['data/emissions_agriculture/Emissions_Agriculture_Manure_Management_E_All_Data_(Normalized).csv',\n",
       "        1757, 'Cattle'],\n",
       "       ['data/emissions_agriculture/Emissions_Agriculture_Manure_Management_E_All_Data_(Normalized).csv',\n",
       "        1054, 'Chickens'],\n",
       "       ['data/emissions_agriculture/Emissions_Agriculture_Manure_left_on_pasture_E_All_Data_(Normalized).csv',\n",
       "        1757, 'Cattle'],\n",
       "       ['data/emissions_agriculture/Emissions_Agriculture_Manure_left_on_pasture_E_All_Data_(Normalized).csv',\n",
       "        1054, 'Chickens'],\n",
       "       ['data/emissions_agriculture/Emissions_Agriculture_Manure_applied_to_soils_E_All_Data_(Normalized).csv',\n",
       "        1757, 'Cattle'],\n",
       "       ['data/emissions_agriculture/Emissions_Agriculture_Manure_applied_to_soils_E_All_Data_(Normalized).csv',\n",
       "        1054, 'Chickens']], dtype=object)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_values[item_values.item.isin(livestock_items)][['file', 'itemcode', 'item']].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that different values for `itemcode` for both \"Chickens\" and \"Cattles\" differ when the measured quantity is realted to Manure. Thus, this might be a discrepancy in the data as it does not appear for other items. However, since the two different item codes appear in un-related csv files, we can keep them that way, and have two itemcodes that map to \"Chickens\" and \"Cattle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.** And finally, land related items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data/emissions_agriculture/Emissions_Agriculture_Burning_Savanna_E_All_Data_(Normalized).csv',\n",
       "       'data/emissions_land/Emissions_Land_Use_Burning_Biomass_E_All_Data_(Normalized).csv',\n",
       "       'data/emissions_land/Emissions_Land_Use_Land_Use_Total_E_All_Data_(Normalized).csv',\n",
       "       'data/environment/Environment_LandUse_E_All_Data_(Normalized).csv',\n",
       "       'data/inputs/Inputs_LandUse_E_All_Data_(Normalized).csv',\n",
       "       'data/emissions_agriculture/Emissions_Agriculture_Burning_Savanna_E_All_Data_(Normalized).csv',\n",
       "       'data/emissions_land/Emissions_Land_Use_Land_Use_Total_E_All_Data_(Normalized).csv',\n",
       "       'data/environment/Environment_LandCover_E_All_Data_(Normalized).csv'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "land_items = [\"Burning - all categories\", \"Cropland\", \"Forest Land\", \"Grassland\"]\n",
    "item_values[item_values.item.isin(land_items)].sort_values(['item', 'file']).file.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking into the description of each csv file, we have found the following explanations:\n",
    "- For `Burning - all categories`:\n",
    "    - for \"Emissions_Agriculture_Burning_Savanna_E_All_Data_(Normalized).csv\", it represents the emissions due to burning of Savanna (all categories) i.e. aggregated over all items\n",
    "    - for \"Emissions_Land_Use_Burning_Biomass_E_All_Data_(Normalized).csv\", it represents the emissions due to the burning of Biomass.\n",
    "- For `Grassland`: \n",
    "    - for \"Emissions_Agriculture_Burning_Savanna_E_All_Data_(Normalized).csv\", it represents the emissions burning of grassland\n",
    "    - for \"Emissions_Land_Use_Land_Use_Total_E_All_Data_(Normalized).csv\" it represents the Green house gass emissions and removals from grasslands\n",
    "    - for \"Environment_LandCover_E_All_Data_(Normalized).csv\" it represents the area of grassland\n",
    "- For `Cropland`:\n",
    "    - for \"Emissions_Land_Use_Land_Use_Total_E_All_Data_(Normalized).csv\" it represents the Green house gass emissions and removals from Croplands\n",
    "    - for \"Environment_LandUse_E_All_Data_(Normalized).csv\" it represents the area of Cropland\n",
    "    - for \"Inputs_LandUse_E_All_Data_(Normalized).csv\" it represents the usage of Cropland"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ADA)",
   "language": "python",
   "name": "ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
