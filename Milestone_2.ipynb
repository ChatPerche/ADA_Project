{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental Impact of Agricultural Practices in the World\n",
    "\n",
    "**ADA Project Milestone 2**\n",
    "\n",
    "This notebook consists of our initial Data Analysis of the FAOSTAT dataset on Food an agriculture. We will first study the contents of the data and its strucuture, before restructuring it in order to start our analysis. Also, some research questions initially asked will be answered by the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Initial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset initially contained 78 csv files, but some of them were discarded as they will not be useful for our analysis. We have selected 43 CSVs that would help us with our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = glob('data/**/**.csv')\n",
    "len(csv_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split those 43 csv into different directories, one for each group of csv. Each group corresponds to one category:\n",
    "```.\n",
    "+-- data/\n",
    "|   +-- emissions_agriculture/\n",
    "|      +-- ...\n",
    "|   +-- emissions_land/\n",
    "|      +-- ...\n",
    "|   +-- environment/\n",
    "|      +-- ...\n",
    "|   +-- forestry/\n",
    "|      +-- ...\n",
    "|   +-- inputs/\n",
    "|      +-- ...\n",
    "|   +-- population/\n",
    "|      +-- ...\n",
    "|   +-- production/\n",
    "|      +-- ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1 Schema consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Checking column names across whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's scan all the csv files and check their schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The found columns, grouped, are:\n",
      "\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'item', 'itemcode', 'unit', 'value', 'year', 'yearcode'] Num files 33\n",
      "['country', 'countrycode', 'element', 'elementcode', 'elementgroup', 'flag', 'item', 'itemcode', 'unit', 'value', 'year'] Num files 4\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'months', 'monthscode', 'unit', 'value', 'year', 'yearcode'] Num files 1\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'item', 'itemcode', 'note', 'unit', 'value', 'year', 'yearcode'] Num files 4\n",
      "['country', 'countrycode', 'element', 'elementcode', 'flag', 'item', 'itemcode', 'unit', 'value', 'year', 'yearcode'] Num files 1\n"
     ]
    }
   ],
   "source": [
    "from data_processing import scan_columns\n",
    "all_columns = scan_columns(csv_files)\n",
    "print(\"The found columns, grouped, are:\\n\")\n",
    "for cols, f in all_columns:\n",
    "    print(list(sorted(cols)), f\"Num files {len(f)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, sometimes the columns `area` and `areacode` are named `country` and `countrycode`. Also, some files have the `note`, `elementgroup` and `months` columns. We will look into those in subsequent steps as we are now simply checking whether column naming is consistent.\n",
    "\n",
    "In order to obtain a more consistent column naming, we will rename `country` to `area` and `countrycode` to `areacode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_rename = {'country': 'area', 'countrycode': 'areacode'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After renaming, we obtain the following columns:\n",
      "\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'item', 'itemcode', 'unit', 'value', 'year', 'yearcode'] Num files 34\n",
      "['area', 'areacode', 'element', 'elementcode', 'elementgroup', 'flag', 'item', 'itemcode', 'unit', 'value', 'year'] Num files 4\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'months', 'monthscode', 'unit', 'value', 'year', 'yearcode'] Num files 1\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'item', 'itemcode', 'note', 'unit', 'value', 'year', 'yearcode'] Num files 4\n"
     ]
    }
   ],
   "source": [
    "all_columns_2 = scan_columns(csv_files, column_rename)\n",
    "print(f\"After renaming, we obtain the following columns:\\n\")\n",
    "for cols, f in all_columns_2:\n",
    "    print(list(sorted(cols)), f\"Num files {len(f)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Checking which columns to drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a few files that have different schemas. One column that we should look into before continuing is `note`, as it is in 4 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([nan]), array([nan]), array([nan]), array([nan])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_processing import load_dataframe\n",
    "def get_column_unique_values(files, col):\n",
    "    # Function that returns the unique values of a column across multiple files\n",
    "    values = []\n",
    "    for f in files:\n",
    "        df = load_dataframe(f, column_rename)\n",
    "        vals = df[col].unique()\n",
    "        values.append(vals)\n",
    "    return values\n",
    "\n",
    "files_with_note = all_columns_2[-1][1]\n",
    "note_values = get_column_unique_values(files_with_note, 'note')\n",
    "note_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, all values for this column are NaN, so we can safely drop the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Checking duplicate columns\n",
    "\n",
    "We figured it would be useful to scan for duplicate columns in each dataframe (i.e. columns with different names but same values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates for [('yearcode', 'year')] in 39 files\n",
      "Duplicates for [('elementgroup', 'elementcode')] in 3 files\n"
     ]
    }
   ],
   "source": [
    "from data_processing import scan_column_duplicates\n",
    "duplicates = scan_column_duplicates(csv_files, column_rename)\n",
    "for c, f in duplicates:\n",
    "    print(f\"Duplicates for {c} in {len(f)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, most files have `year` and `yearcode` columns which are equal. Hence, we can safely drop this column. However, for `elementgroup` and `elementcode`, they are equal in almost all CSV where they appear (3/4), but not all, so we cannot safely drop it without checking. We choose to keep `elementcode` when those two are equal, and keep them both when they are not.\n",
    "\n",
    "Hence, we can define a list of columns to be dropped, but we need to check if they fulfill any of the following conditions:\n",
    " - NaN in all rows\n",
    " - Duplicate with another column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After renaming and dropping columns, we obtain the following columns:\n",
      "\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'item', 'itemcode', 'unit', 'value', 'year'] Num files 41\n",
      "['area', 'areacode', 'element', 'elementcode', 'elementgroup', 'flag', 'item', 'itemcode', 'unit', 'value', 'year'] Num files 1\n",
      "['area', 'areacode', 'element', 'elementcode', 'flag', 'months', 'monthscode', 'unit', 'value', 'year'] Num files 1\n"
     ]
    }
   ],
   "source": [
    "drop_columns = [\"note\", \"yearcode\", \"elementgroup\"]\n",
    "all_columns_3 = scan_columns(csv_files, column_rename, drop_columns)\n",
    "print(f\"After renaming and dropping columns, we obtain the following columns:\\n\")\n",
    "for cols, f in all_columns_3:\n",
    "    print(list(sorted(cols)), f\"Num files {len(f)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 41 files with identical schemas, and 2 files that have a different one:\n",
    " - The file containing the `elementgroup` additional column \n",
    " - The file with monthly data and no `item` and `itemcode` columns\n",
    " \n",
    "To obtain the desired format, we can now call `load_dataframe(<file>, column_rename, drop_columns)` with `column_rename = {'country': 'area', 'countrycode': 'areacode'}` and `drop_columns = [\"note\", \"yearcode\", \"elementgroup\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2 Schema description\n",
    "Now that we have a unified schema for (almost) all csv files, we can start looking into the meaning of each column and their possible value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Area columns\n",
    "\n",
    "We will first look into the columns `area` and `areacode`. According to FAOSTAT's website, each area is defined by a unique areacode, however some areas include other ones, i.e. there are grouped areas in the datasets. We would expect a one-to-one mapping between those two columns. Let's see how this looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that it is indeed a one-to-one mapping, we will append all values from all csv files, and drop duplicates. Then we group by area and see if the length of the group is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area and Areacode is a one-to-one mapping\n"
     ]
    }
   ],
   "source": [
    "from data_processing import get_column_unique_values\n",
    "from utils import is_unique_mapping\n",
    "\n",
    "area_values = get_column_unique_values(csv_files, column_rename, drop_columns, ['area', 'areacode'])\n",
    "if is_unique_mapping(area_values, 'area', 'areacode'):\n",
    "    print(\"Area and Areacode is a one-to-one mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>areacode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>Albania</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>Angola</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Polynesia + (Total)</td>\n",
       "      <td>5504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166548</th>\n",
       "      <td>Svalbard and Jan Mayen Islands</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14537</th>\n",
       "      <td>Bonaire, Sint Eustatius and Saba</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105102</th>\n",
       "      <td>Saint Barthélemy</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113034</th>\n",
       "      <td>Sint Maarten (Dutch Part)</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    area  areacode\n",
       "0                            Afghanistan         2\n",
       "627                              Albania         3\n",
       "1539                             Algeria         4\n",
       "2508                      American Samoa         5\n",
       "2793                              Angola         7\n",
       "...                                  ...       ...\n",
       "422                  Polynesia + (Total)      5504\n",
       "166548    Svalbard and Jan Mayen Islands       260\n",
       "14537   Bonaire, Sint Eustatius and Saba       278\n",
       "105102                  Saint Barthélemy       282\n",
       "113034         Sint Maarten (Dutch Part)       280\n",
       "\n",
       "[336 rows x 2 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some wierd `area` values such as \"Polynesia + (Total)\" represent a group of areas rather than a country. In order to understand how those grouped are formed, we downloaded an additional csv file present on the FAOSTAT website, describing which countries are in those grouped areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countrygroupcode</th>\n",
       "      <th>countrygroup</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>country</th>\n",
       "      <th>m49code</th>\n",
       "      <th>iso2code</th>\n",
       "      <th>iso3code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>4</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>12.0</td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>7</td>\n",
       "      <td>Angola</td>\n",
       "      <td>24.0</td>\n",
       "      <td>AO</td>\n",
       "      <td>AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>53</td>\n",
       "      <td>Benin</td>\n",
       "      <td>204.0</td>\n",
       "      <td>BJ</td>\n",
       "      <td>BEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>20</td>\n",
       "      <td>Botswana</td>\n",
       "      <td>72.0</td>\n",
       "      <td>BW</td>\n",
       "      <td>BWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>British Indian Ocean Territory</td>\n",
       "      <td>86.0</td>\n",
       "      <td>IO</td>\n",
       "      <td>IOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   countrygroupcode countrygroup  countrycode                         country  \\\n",
       "0              5100       Africa            4                         Algeria   \n",
       "1              5100       Africa            7                          Angola   \n",
       "2              5100       Africa           53                           Benin   \n",
       "3              5100       Africa           20                        Botswana   \n",
       "4              5100       Africa           24  British Indian Ocean Territory   \n",
       "\n",
       "   m49code iso2code iso3code  \n",
       "0     12.0       DZ      DZA  \n",
       "1     24.0       AO      AGO  \n",
       "2    204.0       BJ      BEN  \n",
       "3     72.0       BW      BWA  \n",
       "4     86.0       IO      IOT  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_groups = load_dataframe('data/country_groups.csv')\n",
    "country_groups.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, countries are grouped into multiple `countrygroup`, so we know exactly of which countries each group is formed. These country groups are present in the dataset as `area`, meaning there are aggregated values in the dataset. For example: we can find the emissions for \"Algeria\" and for \"Africa\", where the latter is an aggregated value over the whole group. We will need to be careful when aggregating values in the future, as we could account multiple times for one country.\n",
    "\n",
    "We will add a `countrygroupcodes` column to each csv, holding the list of `countrygroupcode` in which the country is (and keep it at NaN for groups).\n",
    "Also the column `iso3code` will help us with plotting maps using `geopandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Element Columns\n",
    "\n",
    "The `element` and `elementcode` represent the measure quantity for a given `item`. A quantity has a name and a unit, which is why we believe these two columns should also have a one-to-one mapping accross the whole dataset. Also, since an `elementcode` potentially uniquely identifies (`element`, `unit`) pair, we might drop those two columns as to make the csv files smaller and easier to manipulate.\n",
    "\n",
    "First let's check if indeed this mapping is one-to-one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_values = get_column_unique_values(csv_files, column_rename, drop_columns, ['elementcode', 'element', 'unit'])\n",
    "is_unique_mapping(element_values, 'elementcode', ['element', 'unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elementcode</th>\n",
       "      <th>element</th>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>Head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>5112</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>1000 Head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>5114</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5510</td>\n",
       "      <td>Production</td>\n",
       "      <td>tonnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5313</td>\n",
       "      <td>Laying</td>\n",
       "      <td>1000 Head</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     elementcode     element       unit\n",
       "0           5111      Stocks       Head\n",
       "171         5112      Stocks  1000 Head\n",
       "684         5114      Stocks         No\n",
       "0           5510  Production     tonnes\n",
       "0           5313      Laying  1000 Head"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `itemcode` uniquely identify (`element`, `unit`) pairs, so we can safely drop those two columns and only use `elementcode`. We will later pivot each csv as to obtain all the `elementcode`s as columns, so we can reduce de number of rows significantly. A mapping using a dictionnary will of course be necessary in order to have a nice GUI where users can select the (element, unit) pair instead of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Item columns\n",
    "\n",
    "According to FAOSTAT, the `item` and `itemcode` columns represent item on which measurements were done. For example an item can be `cattle` and the measurement can be \"CH4 emissions in gigagrams\". \n",
    "Similarly to what we did above, we expect `item` and `itemcode` to have a one-to-one relationship. Let's verify this using the same functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_values = get_column_unique_values(csv_files, column_rename, drop_columns, ['item', 'itemcode'])\n",
    "is_unique_mapping(item_values, 'item', 'itemcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that `item` to `itemcode` is not unique for a few items, let's check those and try to understand why it is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemcode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ammonium nitrate (AN)</th>\n",
       "      <td>{1362, 4003}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ammonium sulphate</th>\n",
       "      <td>{1361, 4002}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burning - all categories</th>\n",
       "      <td>{6795, 6798}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cattle</th>\n",
       "      <td>{866, 1757}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chickens</th>\n",
       "      <td>{1057, 1054}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cropland</th>\n",
       "      <td>{6620, 5070}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disinfectants</th>\n",
       "      <td>{1358, 1351}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forest land</th>\n",
       "      <td>{5065, 6749, 6646}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grassland</th>\n",
       "      <td>{6794, 6983}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mineral Oils</th>\n",
       "      <td>{1354, 1316}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Pesticides nes</th>\n",
       "      <td>{1355, 1359}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other nitrogenous fertilizers, n.e.c.</th>\n",
       "      <td>{4008, 1369}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other potassic fertilizers, n.e.c.</th>\n",
       "      <td>{4018, 1391}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plant Growth Regulators</th>\n",
       "      <td>{1356, 1341}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Potassium sulphate (sulphate of potash) (SOP)</th>\n",
       "      <td>{4017, 1387}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urea</th>\n",
       "      <td>{4001, 1367}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         itemcode\n",
       "item                                                             \n",
       "Ammonium nitrate (AN)                                {1362, 4003}\n",
       "Ammonium sulphate                                    {1361, 4002}\n",
       "Burning - all categories                             {6795, 6798}\n",
       "Cattle                                                {866, 1757}\n",
       "Chickens                                             {1057, 1054}\n",
       "Cropland                                             {6620, 5070}\n",
       "Disinfectants                                        {1358, 1351}\n",
       "Forest land                                    {5065, 6749, 6646}\n",
       "Grassland                                            {6794, 6983}\n",
       "Mineral Oils                                         {1354, 1316}\n",
       "Other Pesticides nes                                 {1355, 1359}\n",
       "Other nitrogenous fertilizers, n.e.c.                {4008, 1369}\n",
       "Other potassic fertilizers, n.e.c.                   {4018, 1391}\n",
       "Plant Growth Regulators                              {1356, 1341}\n",
       "Potassium sulphate (sulphate of potash) (SOP)        {4017, 1387}\n",
       "Urea                                                 {4001, 1367}"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = item_values.groupby('item').agg({'itemcode': set})\n",
    "grouped[grouped.itemcode.apply(len) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some items seem to have multiple (up to 3) different item codes, which doesn't seem very normal. It seems that some of those items correspond to nutrients provided throught fertilizers. Let's see in which files those appear. The items related to nutrients are the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data/inputs/Inputs_FertilizersArchive_E_All_Data_(Normalized).csv',\n",
       "       'data/inputs/Inputs_FertilizersProduct_E_All_Data_(Normalized).csv'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrient_items = [\"Ammonium nitrate (AN)\", \"Ammonium sulphate\", \"Other nitrogenous fertilizers, n.e.c.\", \"Other potassic fertilizers, n.e.c.\", \"Potassium sulphate (sulphate of potash) (SOP)\", \"Urea\"]\n",
    "item_values[item_values.item.isin(nutrient_items)].file.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: explain that one is an Archive and the other is a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data/inputs/Inputs_Pesticides_Use_E_All_Data_(Normalized).csv'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pesticide_items = [\"Disinfectants\", \"Mineral Oils\", \"Other Pesticides nes\", \"Plant Growth Regulators\"]\n",
    "item_values[item_values.item.isin(pesticide_items)].file.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate item for Disinfectants\n",
      "Duplicate item for Mineral Oils\n",
      "Duplicate item for Other Pesticides nes\n",
      "Duplicate item for Plant Growth Regulators\n"
     ]
    }
   ],
   "source": [
    "t = load_dataframe('data/inputs/Inputs_Pesticides_Use_E_All_Data_(Normalized).csv', column_rename, drop_columns)\n",
    "for i in pesticide_items:\n",
    "    item_codes = t[t.item == i].itemcode.unique()\n",
    "    if (t[t.itemcode == item_codes[0]].drop('itemcode', axis=1).values == t[t.itemcode == item_codes[1]].drop('itemcode', axis=1).values).all():\n",
    "        print(f\"Duplicate item for {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data/production/Production_Livestock_E_All_Data_(Normalized).csv',\n",
       "       'data/environment/Environment_LivestockPatterns_E_All_Data_(Normalized).csv',\n",
       "       'data/environment/Environment_LivestockManure_E_All_Data_(Normalized).csv',\n",
       "       'data/emissions_agriculture/Emissions_Agriculture_Enteric_Fermentation_E_All_Data_(Normalized).csv',\n",
       "       'data/emissions_agriculture/Emissions_Agriculture_Manure_Management_E_All_Data_(Normalized).csv',\n",
       "       'data/emissions_agriculture/Emissions_Agriculture_Manure_left_on_pasture_E_All_Data_(Normalized).csv',\n",
       "       'data/emissions_agriculture/Emissions_Agriculture_Manure_applied_to_soils_E_All_Data_(Normalized).csv'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livestock_items = [\"Cattle\", \"Chickens\"]\n",
    "item_values[item_values.item.isin(livestock_items)].file.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data/environment/Environment_LandCover_E_All_Data_(Normalized).csv',\n",
       "       'data/environment/Environment_LandUse_E_All_Data_(Normalized).csv',\n",
       "       'data/emissions_land/Emissions_Land_Use_Land_Use_Total_E_All_Data_(Normalized).csv',\n",
       "       'data/emissions_agriculture/Emissions_Agriculture_Burning_Savanna_E_All_Data_(Normalized).csv',\n",
       "       'data/inputs/Inputs_LandUse_E_All_Data_(Normalized).csv'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "land_items = [\"Burning - all crops\", \"Cropland\", \"Forest Land\", \"Grassland\"]\n",
    "item_values[item_values.item.isin(land_items)].file.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ADA)",
   "language": "python",
   "name": "ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
